{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a word vector using the skip-gram and CBOW models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import gensim\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the airline tweets sentiment dataset, which contains comments (text) related to airlines and their corresponding sentiment. The dataset can be obtained from https://d1p17r2m4rzlbo.cloudfront.net/wp-content/uploads/2016/03/Airline-Sentiment-2-w-AA.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://www.dropbox.com/s/8yq0edd4q908xqw/airline_sentiment.csv?dl=1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sample of the dataset looks as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   airline_sentiment                                               text\n",
       "0                  1  @VirginAmerica plus you've added commercials t...\n",
       "1                  0  @VirginAmerica it's really aggressive to blast...\n",
       "2                  0  @VirginAmerica and it's a really big bad thing...\n",
       "3                  0  @VirginAmerica seriously would pay $30 a fligh...\n",
       "4                  1  @VirginAmerica yes, nearly every time I fly VX..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the preceding text to do the following:\n",
    "* Normalize every word to lower case.\n",
    "* Remove punctuation and retain only numbers and alphabets.\n",
    "* Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "def preprocess(text):\n",
    "    text=text.lower()\n",
    "    text=re.sub('[^0-9a-z]+',' ',text)\n",
    "    words = text.split()\n",
    "    words2 = [i for i in words if i not in stop]\n",
    "    words3=' '.join(words2)\n",
    "    return(words3)\n",
    "data['text'] = data['text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After Preprocessing the Dataset looks as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>virginamerica plus added commercials experienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>virginamerica really aggressive blast obnoxiou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>virginamerica really big bad thing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>virginamerica seriously would pay 30 flight se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>virginamerica yes nearly every time fly vx ear...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   airline_sentiment                                               text\n",
       "0                  1  virginamerica plus added commercials experienc...\n",
       "1                  0  virginamerica really aggressive blast obnoxiou...\n",
       "2                  0                 virginamerica really big bad thing\n",
       "3                  0  virginamerica seriously would pay 30 flight se...\n",
       "4                  1  virginamerica yes nearly every time fly vx ear..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split sentences into a list of tokens so that they can then be passed to gensim. The output of the first sentence should look as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['virginamerica', 'plus', 'added', 'commercials', 'experience', 'tacky']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'][0].split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loop through all the text we have and append it in a list, as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_words=[]\n",
    "for i in range(len(data)):\n",
    "    list_words.append(data['text'][i].split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the first two lists within the list of lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['virginamerica', 'plus', 'added', 'commercials', 'experience', 'tacky'],\n",
       " ['virginamerica',\n",
       "  'really',\n",
       "  'aggressive',\n",
       "  'blast',\n",
       "  'obnoxious',\n",
       "  'entertainment',\n",
       "  'guests',\n",
       "  'faces',\n",
       "  'amp',\n",
       "  'little',\n",
       "  'recourse']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_words[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the Word2Vec model. Define the vector size, context window size to look into, and the minimum count of a word for it to be eligible to have a word vector\n",
    "* size represents the size (dimension) of word vectors.\n",
    "* window represents the context size of words that would be considered.\n",
    "* min_count specifies the minimum frequency based on which a word is considered.\n",
    "* sg represents whether skip-gram used (when sg=1) or CBOW (when sg = 0) used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maninaya\\Anaconda3\\envs\\maninaya\\lib\\site-packages\\gensim\\models\\base_any2vec.py:743: UserWarning: C extension not loaded, training will be slow. Install a C compiler and reinstall gensim for fast training.\n",
      "  \"C extension not loaded, training will be slow. \"\n"
     ]
    }
   ],
   "source": [
    "model = Word2Vec(size=100,window=5,min_count=30, sg=0, alpha = 0.025)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is defined, we will pass our list of lists to build a vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11541"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.build_vocab(list_words)\n",
    "model.corpus_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the vocabulary is built, the final words that would be left after filtering out the words that occur fewer than 30 times in the whole corpus can be found as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['virginamerica', 'plus', 'experience', 'really', 'amp', 'little', 'big', 'bad', 'thing', 'seriously', 'would', 'pay', '30', 'flight', 'seats', 'flying', 'yes', 'every', 'time', 'fly', 'go', 'away', 'well', 'amazing', 'arrived', 'hour', 'early', 'good', 'lt', '3', 'pretty', 'much', 'better', 'great', 'deal', 'already', '2nd', 'trip', 'even', '1st', 'yet', 'u', 'take', 'travel', 'http', 'co', 'thanks', 'sfo', 'still', 'mia', 'first', 'lax', 'mco', 'heard', 'nothing', 'things', 'flew', 'nyc', 'last', 'week', 'sit', 'seat', 'due', 'two', 'either', 'help', 'know', 'awesome', 'bos', 'fll', 'please', 'want', 'may', 'three', 'times', 'available', 'love', 'feel', 'guys', 'gave', 'free', 'status', 'weeks', 'called', 'response', 'happened', '2', 'ur', 'food', 'options', 'least', 'say', 'site', 'able', 'anything', 'next', '6', 'hrs', 'fail', 'get', 'air', 'hi', 'cool', 'add', 'name', 'booking', 'problems', 'left', 'iad', 'today', 'one', 'answering', 'f', 'number', 'return', 'phone', 'call', 'use', 'online', 'service', 'option', 'could', 'start', 'flights', 'end', 'year', 'via', 'way', 'best', 'ever', 'done', 'airline', 'around', 'support', 'working', 'beyond', 'hey', 'hard', 'getting', 'account', 'reason', 'rock', 'wow', 'though', 'lga', 'gt', 'trying', 'book', 'since', 'never', 'thx', 'need', '4', 'ago', 'someone', 'hold', '40', '50', 'minutes', 'earlier', 'la', 'tonight', '11', 'us', 'everything', 'fine', 'lost', 'bag', 'needs', 'new', 'plane', 'crew', 'airlines', 'like', 'sat', 'morning', 'going', 'customer', 'speak', 'human', 'asap', 'thank', 'southwestair', 'jetblue', 'member', 'team', 'im', '100', 'delayed', 'late', 'cancelled', 'four', 'business', 'wife', 'booked', 'back', 'tv', 'disappointed', 'flightled', 'went', 'jfk', 'landed', 'check', 'friendly', 'website', 'another', 'tried', 'let', 'passengers', 'leave', 'told', 'class', 'find', 'reservation', 'anyone', 'miss', 'missed', 'direct', 'vegas', 'bought', 'people', 'customerservice', 'line', 'hung', 'card', 'info', 'come', 'phl', 'horrible', 'stop', 'easy', 'change', 'helpful', 'rep', 'front', 'right', 'ticket', 'b', 'c', 'gate', 'las', 'waited', 'problem', 'min', 'delay', 'connecting', 'seems', 'long', 'moved', 'home', 'san', 'scheduled', '9', 'hours', 'wait', 'calling', 'completely', 'month', 'customers', 'process', 'link', 'tsa', 'terrible', 'hotel', 'said', 'sorry', 'assistance', 'yesterday', 'give', 'longer', 'pls', 'making', 'always', 'buy', 'frustrated', 'think', 'paying', 'extra', 'rt', 'luggage', 'might', 'world', 'provide', 'cant', 'weather', 'dallas', 'staff', 'super', 'paid', 'offer', 'fee', 'upgrade', 'sad', 'question', 'possible', 'giving', 'together', 'dc', 'work', 'understand', 'dm', 'answer', 'policy', 'mean', 'checking', 'tickets', 'happy', 'error', 'contact', 'minute', 'reschedule', 'fix', 'got', 'checked', 'email', 'tomorrow', 'unacceptable', 'flighted', 'stuck', '1', 'offered', 'look', 'agent', 'airport', 'reply', 'baggage', 'waiting', 'checkin', 'desk', 'open', 'ewr', 'united', 'follow', 'many', 'worse', 'respond', 'money', 'stranded', 'landing', '10', 'days', 'confirmation', 'claim', '8', 'rebook', 'lot', 'see', 'worst', 'wrong', 'lose', 'suck', 'issue', 'flightlation', 'w', 'kids', 'boston', 'guy', 'high', 'quick', 'apparently', 'sitting', 'keep', 'ny', 'pilots', 'job', 'snow', 'row', 'mechanical', 'handle', 'twitter', 'charged', 'refund', 'broken', 'points', 'looking', 'forward', 'rescheduled', 'cost', '800', 'show', 'wish', 'attendant', 'something', 'departure', 'fun', 'different', 'helping', 'passenger', 'flt', 'city', 'destination', 'missing', 'coming', 'entire', 'confirmed', 'treat', 'wtf', 'inconvenience', 'full', 'dfw', 'boarding', 'place', 'makes', 'pilot', 'dca', 'sent', 'past', 'club', 'came', 'monday', 'safety', 'day', 'wanted', 'newark', 'hope', 'board', 'helped', 'looks', 'https', 'less', 'half', 'price', 'taking', 'care', 'several', 'glad', 'took', 'years', 'night', 'try', 'purchase', 'hoping', 'carry', 'empty', 'spoke', 'loyal', 'received', 'southwest', 'family', 'ok', 'using', 'soon', 'car', 'sucks', 'cust', 'second', 'chance', 'joke', 'credit', 'request', 'planes', 'thought', 'computer', '15', 'cannot', 'make', 'address', 'made', 'also', 'app', 'system', 'instead', 'charge', 'houston', 'finally', 'future', 'poor', '5', 'group', 'room', 'bags', 'sure', '12', 'shit', 'stay', 'nice', 'wifi', 'saying', 'whole', 'person', 'calls', 'ask', 'flighting', 'luck', '24', 'fees', 'philly', 'point', 'says', 'update', 'reps', 'actually', 'lack', 'ord', 'connections', 'boarded', 'issues', 'oh', 'supposed', 'ridiculous', 'send', 'voucher', 'company', 'maybe', 'drive', 'talk', 'flightr', 'platinum', 'international', 'run', 'agents', 'rude', 'iah', 'charlotte', 'non', 'guess', 'form', 'ground', 'else', 'appreciate', 'tarmac', 'pass', 'enough', 'denver', 'put', 'found', 'supervisor', 'months', 'thru', 'connection', 'upset', 'employees', 'old', '7', 'miles', 'american', 'telling', 'delta', 'attendants', 'seem', 'believe', 'bc', 'asking', 'details', 'everyone', 'ua', 'despite', 'updates', 'given', 'hear', 'apology', 'rather', 'zero', 'americanair', 'asked', 'yeah', '25', 'leaving', 'message', 'complaint', 'awful', 'jet', 'atl', 'happens', 'traveling', 'communication', 'far', 'top', 'unitedairlines', 'extremely', 'real', 'without', 'clothes', 'hr', 'terminal', '20', 'mins', 'vacation', 'sleep', 'compensation', 'case', 'happen', 'delivered', 'arrive', 'employee', 'delays', 'taken', 'answers', 'clt', 'idea', 'frustrating', 'figure', 'counter', 'tell', 'fact', 'needed', 'means', 'bwi', 'pm', 'expect', 'fixed', 'unable', 'life', 'phones', 'chicago', 'den', 'fleet', 'gives', 'spent', 'situation', 'list', 'changes', '200', 'used', 'reservations', 'leg', 'reflight', '45', 'changed', 'reach', 'tweet', 'maintenance', 'friend', 'twice', 'counting', 'rebooked', 'sunday', 'sense', 'hate', 'huge', 'standby', 'hopefully', 'usairways', 'almost', 'pick', 'multiple', 'lol', 'crazy', 'gets', 'miami', 'fault', 'sending', 'losing', 'switch', 'aa', 'flightlations', 'seen', 'appreciated', 'media', 'runway', 'live', 'information', 'busy', 'dont', 'disconnected', 'water', 'kind', 'phx', 'automated', 'sw', 'holding', 'swa', 'destinationdragons', 'usair', 'blue', 'fleek', 'airways'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vocab.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model by specifying the total number of examples (lists) that need to be considered and the number of epochs to be run\n",
    "* list_words (the list of words) is the input.\n",
    "* total_examples represents the total number of lists to be considered.\n",
    "* epochs is the number of epochs to be run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6807709, 12585800)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(list_words, total_examples=model.corpus_count, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the word vectors of a given word (month), as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maninaya\\Anaconda3\\envs\\maninaya\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.8686405 ,  0.6634897 ,  0.11039618,  0.9978436 ,  2.7559671 ,\n",
       "       -0.0642437 , -0.8825282 ,  0.46670377,  0.644586  , -0.3504269 ,\n",
       "        1.4642848 ,  0.0852625 , -0.9671676 ,  0.82810646, -2.6629035 ,\n",
       "       -0.5137696 , -0.15381114, -0.5468838 ,  1.5480644 ,  1.1200687 ,\n",
       "       -0.02062936, -0.81567293,  0.59633356, -2.3973215 ,  0.44290587,\n",
       "        1.0673373 ,  0.33287972, -1.367445  , -2.3053613 , -2.91107   ,\n",
       "        0.8846327 ,  0.2501367 ,  1.7979026 ,  0.44279793, -0.62871486,\n",
       "        1.9821651 , -0.37631744,  0.60704523,  0.11040852, -0.27083874,\n",
       "        2.1312585 , -1.2533792 , -4.6724534 ,  0.801622  ,  0.32228664,\n",
       "        1.0946869 ,  0.15452932, -0.01446615, -0.17676151, -0.39306486,\n",
       "        0.21955755,  0.08783851,  0.3999704 ,  0.1595587 ,  0.70441324,\n",
       "        1.6002792 , -1.2129657 ,  1.5463489 ,  2.9143138 , -2.3764787 ,\n",
       "       -1.400456  ,  1.3655556 , -1.2308736 , -0.30149913, -0.404759  ,\n",
       "        0.68080676,  1.5798203 ,  0.13690098,  0.43629053,  2.7819476 ,\n",
       "       -1.9794698 ,  0.7697483 ,  0.20767376, -1.4494764 ,  0.73699105,\n",
       "       -1.6981641 , -1.2620844 , -0.4807502 , -0.80582315, -1.9606714 ,\n",
       "       -0.96954066,  1.4767592 , -0.46435887, -0.6939772 ,  1.0143878 ,\n",
       "       -0.4924941 ,  0.5747426 ,  0.04907424, -0.48181924, -1.3113906 ,\n",
       "       -1.3406587 , -0.92792374,  0.34201303,  0.542277  ,  0.9159806 ,\n",
       "        0.03797334, -0.44676626, -2.500845  ,  0.8992883 , -0.2359156 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['month']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The similarity between two words can be calculated as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maninaya\\Anaconda3\\envs\\maninaya\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.49794415"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('month','year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The words that are most similar to a given word is calculated as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maninaya\\Anaconda3\\envs\\maninaya\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('year', 0.4979441165924072),\n",
       " ('week', 0.48616230487823486),\n",
       " ('months', 0.3903491497039795),\n",
       " ('weeks', 0.35901960730552673),\n",
       " ('leg', 0.3421023488044739),\n",
       " ('row', 0.29487115144729614),\n",
       " ('days', 0.2835123836994171),\n",
       " ('account', 0.26402658224105835),\n",
       " ('lt', 0.26270467042922974),\n",
       " ('miles', 0.25241610407829285)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('month')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, while these similarities look low and some of the most similar words do not look intuitive, it will be more realistic once we train on a huge dataset than the 11,000-tweet dataset that we have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's see the output of most similar words to the word \"month\", when we run the model for a few number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maninaya\\Anaconda3\\envs\\maninaya\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('years', 0.9995688796043396),\n",
       " ('high', 0.9995490312576294),\n",
       " ('sw', 0.9995419383049011),\n",
       " ('means', 0.9995293617248535),\n",
       " ('around', 0.9995282292366028),\n",
       " ('fault', 0.9995271563529968),\n",
       " ('extremely', 0.9995233416557312),\n",
       " ('also', 0.9995226860046387),\n",
       " ('asking', 0.9995217323303223),\n",
       " ('case', 0.9995102882385254)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Word2Vec(size=100,window=5,min_count=30, sg=0)\n",
    "model.build_vocab(list_words)\n",
    "model.train(list_words, total_examples=model.corpus_count, epochs=5)\n",
    "model.most_similar('month')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
